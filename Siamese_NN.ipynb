{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Siamese NN.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "authorship_tag": "ABX9TyNYv0kYgiB8xFgDx8VSWT70",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/RahulXavier/HEXA/blob/master/Siamese_NN.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Kb9ePrf4qMFQ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "!pip install wandb\n",
        "import random\n",
        "import numpy as np\n",
        "import keras\n",
        "import wandb\n",
        "from wandb.keras import WandbCallback\n",
        "from keras.models import Sequential, Model\n",
        "from keras.layers import Flatten, Dense, Concatenate, Dot, Lambda, Input\n",
        "from keras.optimizers import Adam\n",
        "import matplotlib.pyplot as plt\n",
        "from google.colab import drive\n",
        "import os\n",
        "import cv2\n",
        "from google.colab.patches import cv2_imshow   #cv2_imshow(x_train[1]) #To display images\n",
        "from random import randint"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "F0zAms6iqUv9",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "drive.mount('/content/drive')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZFVVX3GA1s49",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "'''\n",
        "    MAP\n",
        "\n",
        "    1 - Reenu\n",
        "    2 - Renie\n",
        "    3 - Sandra F\n",
        "    4 - Shoalia\n",
        "    5 - Shwetha Sandeep\n",
        "    6 - Sweta Satish\n",
        "    7 - Tabita\n",
        "    8 - Vivek SP\n",
        "\n",
        "'''"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "duhN4Ip-xrKl",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 168
        },
        "outputId": "b249c31a-e2ce-41ea-eb08-3ed1d13f0198"
      },
      "source": [
        "x_train = []\n",
        "y_train = []\n",
        "x_test = []\n",
        "y_test = []\n",
        "size = 64\n",
        "\n",
        "directory = r'/content/drive/My Drive/Colab Notebooks/Project-Sign samples/Signature Datasets/Training/Reenu'\n",
        "for filename in os.listdir(directory):\n",
        "    file = '/content/drive/My Drive/Colab Notebooks/Project-Sign samples/Signature Datasets/Training/Reenu/' + filename\n",
        "    im = cv2.imread(file,0)  # 0 for greyscale\n",
        "    im = cv2.resize(im, dsize=(size, size), interpolation=cv2.INTER_CUBIC)\n",
        "    x_train.append(im)\n",
        "    y_train.append(1)\n",
        "    value = randint(1,10)\n",
        "    if value<4 :\n",
        "        x_test.append(im)\n",
        "        y_test.append(1)\n",
        "print('1: Processed ;',end = ' ')\n",
        "print(len(os.listdir(directory)),' images converted')\n",
        "\n",
        "directory = r'/content/drive/My Drive/Colab Notebooks/Project-Sign samples/Signature Datasets/Training/Renie'\n",
        "for filename in os.listdir(directory):\n",
        "    file = '/content/drive/My Drive/Colab Notebooks/Project-Sign samples/Signature Datasets/Training/Renie/' + filename\n",
        "    im = cv2.imread(file,0)  # 0 for greyscale\n",
        "    im = cv2.resize(im, dsize=(size, size), interpolation=cv2.INTER_CUBIC)\n",
        "    x_train.append(im)\n",
        "    y_train.append(2)\n",
        "    value = randint(1,10)\n",
        "    if value<4 :\n",
        "        x_test.append(im)\n",
        "        y_test.append(2)\n",
        "print('2: Processed ;',end = ' ')\n",
        "print(len(os.listdir(directory)),' images converted')\n",
        "\n",
        "directory = r'/content/drive/My Drive/Colab Notebooks/Project-Sign samples/Signature Datasets/Training/Sandra Fulgence'\n",
        "for filename in os.listdir(directory):\n",
        "    file = '/content/drive/My Drive/Colab Notebooks/Project-Sign samples/Signature Datasets/Training/Sandra Fulgence/' + filename\n",
        "    im = cv2.imread(file,0)  # 0 for greyscale\n",
        "    im = cv2.resize(im, dsize=(size, size), interpolation=cv2.INTER_CUBIC)\n",
        "    x_train.append(im)\n",
        "    y_train.append(3)\n",
        "    value = randint(1,10)\n",
        "    if value<4 :\n",
        "        x_test.append(im)\n",
        "        y_test.append(3)\n",
        "print('3: Processed ;',end=' ')\n",
        "print(len(os.listdir(directory)),' images converted')\n",
        "\n",
        "directory = r'/content/drive/My Drive/Colab Notebooks/Project-Sign samples/Signature Datasets/Training/Shoalia'\n",
        "for filename in os.listdir(directory):\n",
        "    file = '/content/drive/My Drive/Colab Notebooks/Project-Sign samples/Signature Datasets/Training/Shoalia/' + filename\n",
        "    im = cv2.imread(file,0)  # 0 for greyscale\n",
        "    im = cv2.resize(im, dsize=(size, size), interpolation=cv2.INTER_CUBIC)\n",
        "    x_train.append(im)\n",
        "    y_train.append(4)\n",
        "    value = randint(1,10)\n",
        "    if value<4 :\n",
        "        x_test.append(im)\n",
        "        y_test.append(4)\n",
        "print('4: Processed ;',end =' ')\n",
        "print(len(os.listdir(directory)),' images converted')\n",
        "\n",
        "directory = r'/content/drive/My Drive/Colab Notebooks/Project-Sign samples/Signature Datasets/Training/Shwetha Sandeep'\n",
        "for filename in os.listdir(directory):\n",
        "    file = '/content/drive/My Drive/Colab Notebooks/Project-Sign samples/Signature Datasets/Training/Shwetha Sandeep/' + filename\n",
        "    im = cv2.imread(file,0)  # 0 for greyscale\n",
        "    im = cv2.resize(im, dsize=(size, size), interpolation=cv2.INTER_CUBIC)\n",
        "    x_train.append(im)\n",
        "    y_train.append(5)\n",
        "    value = randint(1,10)\n",
        "    if value<4 :\n",
        "        x_test.append(im)\n",
        "        y_test.append(5)\n",
        "print('5: Processed ;', end = ' ')\n",
        "print(len(os.listdir(directory)),' images converted')\n",
        "\n",
        "directory = r'/content/drive/My Drive/Colab Notebooks/Project-Sign samples/Signature Datasets/Training/Sweta Satish'\n",
        "for filename in os.listdir(directory):\n",
        "    file = '/content/drive/My Drive/Colab Notebooks/Project-Sign samples/Signature Datasets/Training/Sweta Satish/' + filename\n",
        "    im = cv2.imread(file,0)  # 0 for greyscale\n",
        "    im = cv2.resize(im, dsize=(size, size), interpolation=cv2.INTER_CUBIC)\n",
        "    x_train.append(im)\n",
        "    y_train.append(6)\n",
        "    value = randint(1,10)\n",
        "    if value<4 :\n",
        "        x_test.append(im)\n",
        "        y_test.append(6)\n",
        "print('6: Processed ;',end = ' ')\n",
        "print(len(os.listdir(directory)),' images converted')\n",
        "\n",
        "directory = r'/content/drive/My Drive/Colab Notebooks/Project-Sign samples/Signature Datasets/Training/Tabitha'\n",
        "for filename in os.listdir(directory):\n",
        "    file = '/content/drive/My Drive/Colab Notebooks/Project-Sign samples/Signature Datasets/Training/Tabitha/' + filename\n",
        "    im = cv2.imread(file,0)  # 0 for greyscale\n",
        "    im = cv2.resize(im, dsize=(size, size), interpolation=cv2.INTER_CUBIC)\n",
        "    x_train.append(im)\n",
        "    y_train.append(7)\n",
        "    value = randint(1,10)\n",
        "    if value<4 :\n",
        "        x_test.append(im)\n",
        "        y_test.append(7)\n",
        "print('7: Processed ;',end = ' ')\n",
        "print(len(os.listdir(directory)),' images converted')\n",
        "\n",
        "directory = r'/content/drive/My Drive/Colab Notebooks/Project-Sign samples/Signature Datasets/Training/Vivek SP'\n",
        "for filename in os.listdir(directory):\n",
        "    file = '/content/drive/My Drive/Colab Notebooks/Project-Sign samples/Signature Datasets/Training/Vivek SP/' + filename\n",
        "    im = cv2.imread(file,0)  # 0 for greyscale\n",
        "    im = cv2.resize(im, dsize=(size, size), interpolation=cv2.INTER_CUBIC)\n",
        "    x_train.append(im)\n",
        "    y_train.append(8)\n",
        "    value = randint(1,10)\n",
        "    if value<4 :\n",
        "        x_test.append(im)\n",
        "        y_test.append(8)\n",
        "print('8: Processed ;',end = ' ')\n",
        "print(len(os.listdir(directory)),' images converted')\n",
        "\n",
        "print('Length of dataset: ',len(x_train))\n",
        "\n",
        "from numpy import save\n",
        "save('/content/drive/My Drive/Colab Notebooks/SNN data/x_train.npy', x_train)\n",
        "save('/content/drive/My Drive/Colab Notebooks/SNN data/y_train.npy', y_train)\n",
        "save('/content/drive/My Drive/Colab Notebooks/SNN data/x_test.npy', x_test)\n",
        "save('/content/drive/My Drive/Colab Notebooks/SNN data/y_test.npy', y_test)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "1: Processed ; 87  images converted\n",
            "2: Processed ; 87  images converted\n",
            "3: Processed ; 87  images converted\n",
            "4: Processed ; 87  images converted\n",
            "5: Processed ; 87  images converted\n",
            "6: Processed ; 87  images converted\n",
            "7: Processed ; 87  images converted\n",
            "8: Processed ; 87  images converted\n",
            "Length of dataset:  696\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wl5IykUf454O",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from numpy import load\n",
        "x_train = load('/content/drive/My Drive/Colab Notebooks/SNN data/x_train.npy')\n",
        "y_train = load('/content/drive/My Drive/Colab Notebooks/SNN data/y_train.npy')\n",
        "x_test = load('/content/drive/My Drive/Colab Notebooks/SNN data/x_test.npy')\n",
        "y_test = load('/content/drive/My Drive/Colab Notebooks/SNN data/y_test.npy')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "f7IELrWm7rM0",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#Visulaize dataset\n",
        "cv2_imshow(x_train[300])\n",
        "print(x_train[300])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "x_H6T5ic7Wi1",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#Normalising the pixels\n",
        "x_train = np.true_divide(x_train,255)\n",
        "x_test = np.true_divide(x_test,255)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hoKINkv-GyMu",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "b2bb67da-0509-40cb-dfd3-e0ecec30911a"
      },
      "source": [
        "'''\n",
        "    MAP\n",
        "\n",
        "    1 - Reenu - [0:86]\n",
        "    2 - Renie - [87:173]\n",
        "    3 - Sandra F - [174:260]\n",
        "    4 - Shoalia - [261:347]\n",
        "    5 - Shwetha Sandeep - [348:434]\n",
        "    6 - Sweta Satish - [435:521]\n",
        "    7 - Tabita - [522:608]\n",
        "    8 - Vivek SP - [609:695]\n",
        "\n",
        "'''\n",
        "#print(y_train[695])\n",
        "print('Resolution is: ',len(x_train[1]))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Resolution is:  64\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fazZtxv4Ko8I",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 151
        },
        "outputId": "f9d1e555-d3ca-450e-d0af-d41b434057dd"
      },
      "source": [
        "pairs_train = []\n",
        "labels_train = []\n",
        "\n",
        "# Adding 2 matching & 7 unmatching image-pairs for each image\n",
        "# So (2+7)*87*8 = 6264 pairs in dataset\n",
        "# Label : 1-Match ; 0-Unmatch\n",
        "\n",
        "for i in range(0,87):            #1 - Reenu - [0:86]\n",
        "    source_img = x_train[i]\n",
        "    matching_img_1 = x_train[randint(0,86)]\n",
        "    matching_img_2 = x_train[randint(0,86)]\n",
        "    unmatch_img_2 = x_train[randint(87,173)]\n",
        "    unmatch_img_3 = x_train[randint(174,260)]\n",
        "    unmatch_img_4 = x_train[randint(261,347)]\n",
        "    unmatch_img_5 = x_train[randint(348,434)]\n",
        "    unmatch_img_6 = x_train[randint(435,521)]\n",
        "    unmatch_img_7 = x_train[randint(522,608)]\n",
        "    unmatch_img_8 = x_train[randint(609,695)]\n",
        "    pairs_train.extend([[source_img,matching_img_1],\n",
        "                  [source_img,matching_img_2],\n",
        "                  [source_img,unmatch_img_2],\n",
        "                  [source_img,unmatch_img_3],\n",
        "                  [source_img,unmatch_img_4],\n",
        "                  [source_img,unmatch_img_5],\n",
        "                  [source_img,unmatch_img_6],\n",
        "                  [source_img,unmatch_img_7],\n",
        "                  [source_img,unmatch_img_8]])\n",
        "    labels_train.extend([1,1,0,0,0,0,0,0,0])\n",
        "print('Progress: ',len(pairs_train),'/6264')\n",
        "\n",
        "for i in range(87,174):         #2 - Renie - [87:173]\n",
        "    source_img = x_train[i]\n",
        "    matching_img_1 = x_train[randint(87,173)]\n",
        "    matching_img_2 = x_train[randint(87,173)]\n",
        "    unmatch_img_1 = x_train[randint(0,86)]\n",
        "    unmatch_img_3 = x_train[randint(174,260)]\n",
        "    unmatch_img_4 = x_train[randint(261,347)]\n",
        "    unmatch_img_5 = x_train[randint(348,434)]\n",
        "    unmatch_img_6 = x_train[randint(435,521)]\n",
        "    unmatch_img_7 = x_train[randint(522,608)]\n",
        "    unmatch_img_8 = x_train[randint(609,695)]\n",
        "    pairs_train.extend([[source_img,matching_img_1],\n",
        "                  [source_img,matching_img_2],\n",
        "                  [source_img,unmatch_img_1],\n",
        "                  [source_img,unmatch_img_3],\n",
        "                  [source_img,unmatch_img_4],\n",
        "                  [source_img,unmatch_img_5],\n",
        "                  [source_img,unmatch_img_6],\n",
        "                  [source_img,unmatch_img_7],\n",
        "                  [source_img,unmatch_img_8]])\n",
        "    labels_train.extend([1,1,0,0,0,0,0,0,0])\n",
        "print('Progress: ',len(pairs_train),'/6264')\n",
        "\n",
        "for i in range(174,261):       #3 - Sandra F - [174:260]\n",
        "    source_img = x_train[i]\n",
        "    matching_img_1 = x_train[randint(174,260)]\n",
        "    matching_img_2 = x_train[randint(174,260)]\n",
        "    unmatch_img_1 = x_train[randint(0,86)]\n",
        "    unmatch_img_2 = x_train[randint(87,173)]\n",
        "    unmatch_img_4 = x_train[randint(261,347)]\n",
        "    unmatch_img_5 = x_train[randint(348,434)]\n",
        "    unmatch_img_6 = x_train[randint(435,521)]\n",
        "    unmatch_img_7 = x_train[randint(522,608)]\n",
        "    unmatch_img_8 = x_train[randint(609,695)]\n",
        "    pairs_train.extend([[source_img,matching_img_1],\n",
        "                  [source_img,matching_img_2],\n",
        "                  [source_img,unmatch_img_1],\n",
        "                  [source_img,unmatch_img_2],\n",
        "                  [source_img,unmatch_img_4],\n",
        "                  [source_img,unmatch_img_5],\n",
        "                  [source_img,unmatch_img_6],\n",
        "                  [source_img,unmatch_img_7],\n",
        "                  [source_img,unmatch_img_8]])\n",
        "    labels_train.extend([1,1,0,0,0,0,0,0,0])\n",
        "print('Progress: ',len(pairs_train),'/6264')\n",
        "\n",
        "for i in range(261,348):       #4 - Shoalia - [261:347]\n",
        "    source_img = x_train[i]\n",
        "    matching_img_1 = x_train[randint(261,347)]\n",
        "    matching_img_2 = x_train[randint(261,347)]\n",
        "    unmatch_img_1 = x_train[randint(0,86)]\n",
        "    unmatch_img_2 = x_train[randint(87,173)]\n",
        "    unmatch_img_3 = x_train[randint(174,260)]\n",
        "    unmatch_img_5 = x_train[randint(348,434)]\n",
        "    unmatch_img_6 = x_train[randint(435,521)]\n",
        "    unmatch_img_7 = x_train[randint(522,608)]\n",
        "    unmatch_img_8 = x_train[randint(609,695)]\n",
        "    pairs_train.extend([[source_img,matching_img_1],\n",
        "                  [source_img,matching_img_2],\n",
        "                  [source_img,unmatch_img_1],\n",
        "                  [source_img,unmatch_img_2],\n",
        "                  [source_img,unmatch_img_3],\n",
        "                  [source_img,unmatch_img_5],\n",
        "                  [source_img,unmatch_img_6],\n",
        "                  [source_img,unmatch_img_7],\n",
        "                  [source_img,unmatch_img_8]])\n",
        "    labels_train.extend([1,1,0,0,0,0,0,0,0])\n",
        "print('Progress: ',len(pairs_train),'/6264')\n",
        "\n",
        "for i in range(348,435):       #5 - Shwetha Sandeep - [348:434]\n",
        "    source_img = x_train[i]\n",
        "    matching_img_1 = x_train[randint(348,434)]\n",
        "    matching_img_2 = x_train[randint(348,434)]\n",
        "    unmatch_img_1 = x_train[randint(0,86)]\n",
        "    unmatch_img_2 = x_train[randint(87,173)]\n",
        "    unmatch_img_3 = x_train[randint(174,260)]\n",
        "    unmatch_img_4 = x_train[randint(261,347)]\n",
        "    unmatch_img_6 = x_train[randint(435,521)]\n",
        "    unmatch_img_7 = x_train[randint(522,608)]\n",
        "    unmatch_img_8 = x_train[randint(609,695)]\n",
        "    pairs_train.extend([[source_img,matching_img_1],\n",
        "                  [source_img,matching_img_2],\n",
        "                  [source_img,unmatch_img_1],\n",
        "                  [source_img,unmatch_img_2],\n",
        "                  [source_img,unmatch_img_3],\n",
        "                  [source_img,unmatch_img_4],\n",
        "                  [source_img,unmatch_img_6],\n",
        "                  [source_img,unmatch_img_7],\n",
        "                  [source_img,unmatch_img_8]])\n",
        "    labels_train.extend([1,1,0,0,0,0,0,0,0])\n",
        "print('Progress: ',len(pairs_train),'/6264')\n",
        "\n",
        "for i in range(435,522):       #6 - Sweta Satish - [435:521]\n",
        "    source_img = x_train[i]\n",
        "    matching_img_1 = x_train[randint(435,521)]\n",
        "    matching_img_2 = x_train[randint(435,521)]\n",
        "    unmatch_img_1 = x_train[randint(0,86)]\n",
        "    unmatch_img_2 = x_train[randint(87,173)]\n",
        "    unmatch_img_3 = x_train[randint(174,260)]\n",
        "    unmatch_img_4 = x_train[randint(261,347)]\n",
        "    unmatch_img_5 = x_train[randint(348,434)]\n",
        "    unmatch_img_7 = x_train[randint(522,608)]\n",
        "    unmatch_img_8 = x_train[randint(609,695)]\n",
        "    pairs_train.extend([[source_img,matching_img_1],\n",
        "                  [source_img,matching_img_2],\n",
        "                  [source_img,unmatch_img_1],\n",
        "                  [source_img,unmatch_img_2],\n",
        "                  [source_img,unmatch_img_3],\n",
        "                  [source_img,unmatch_img_4],\n",
        "                  [source_img,unmatch_img_5],\n",
        "                  [source_img,unmatch_img_7],\n",
        "                  [source_img,unmatch_img_8]])\n",
        "    labels_train.extend([1,1,0,0,0,0,0,0,0])\n",
        "print('Progress: ',len(pairs_train),'/6264')\n",
        "\n",
        "for i in range(522,609):       #7 - Tabita - [522:608]\n",
        "    source_img = x_train[i]\n",
        "    matching_img_1 = x_train[randint(522,608)]\n",
        "    matching_img_2 = x_train[randint(522,608)]\n",
        "    unmatch_img_1 = x_train[randint(0,86)]\n",
        "    unmatch_img_2 = x_train[randint(87,173)]\n",
        "    unmatch_img_3 = x_train[randint(174,260)]\n",
        "    unmatch_img_4 = x_train[randint(261,347)]\n",
        "    unmatch_img_5 = x_train[randint(348,434)]\n",
        "    unmatch_img_6 = x_train[randint(435,521)]\n",
        "    unmatch_img_8 = x_train[randint(609,695)]\n",
        "    pairs_train.extend([[source_img,matching_img_1],\n",
        "                  [source_img,matching_img_2],\n",
        "                  [source_img,unmatch_img_1],\n",
        "                  [source_img,unmatch_img_2],\n",
        "                  [source_img,unmatch_img_3],\n",
        "                  [source_img,unmatch_img_4],\n",
        "                  [source_img,unmatch_img_5],\n",
        "                  [source_img,unmatch_img_6],\n",
        "                  [source_img,unmatch_img_8]])\n",
        "    labels_train.extend([1,1,0,0,0,0,0,0,0])\n",
        "print('Progress: ',len(pairs_train),'/6264')\n",
        "\n",
        "for i in range(609,696):       #8 - Vivek SP - [609:695]\n",
        "    source_img = x_train[i]\n",
        "    matching_img_1 = x_train[randint(609,695)]\n",
        "    matching_img_2 = x_train[randint(609,695)]\n",
        "    unmatch_img_1 = x_train[randint(0,86)]\n",
        "    unmatch_img_2 = x_train[randint(87,173)]\n",
        "    unmatch_img_3 = x_train[randint(174,260)]\n",
        "    unmatch_img_4 = x_train[randint(261,347)]\n",
        "    unmatch_img_5 = x_train[randint(348,434)]\n",
        "    unmatch_img_6 = x_train[randint(435,521)]\n",
        "    unmatch_img_7 = x_train[randint(522,608)]\n",
        "    pairs_train.extend([[source_img,matching_img_1],\n",
        "                  [source_img,matching_img_2],\n",
        "                  [source_img,unmatch_img_1],\n",
        "                  [source_img,unmatch_img_2],\n",
        "                  [source_img,unmatch_img_3],\n",
        "                  [source_img,unmatch_img_4],\n",
        "                  [source_img,unmatch_img_5],\n",
        "                  [source_img,unmatch_img_6],\n",
        "                  [source_img,unmatch_img_8]])\n",
        "    labels_train.extend([1,1,0,0,0,0,0,0,0])\n",
        "print('Progress: ',len(pairs_train),'/6264')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Progress:  783 /6264\n",
            "Progress:  1566 /6264\n",
            "Progress:  2349 /6264\n",
            "Progress:  3132 /6264\n",
            "Progress:  3915 /6264\n",
            "Progress:  4698 /6264\n",
            "Progress:  5481 /6264\n",
            "Progress:  6264 /6264\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "S-0ykKGMf1NZ",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 151
        },
        "outputId": "60c7e3b5-8092-4293-d87f-e8075b09541d"
      },
      "source": [
        "pairs_test = []\n",
        "labels_test = []\n",
        "\n",
        "# Adding 1 matching & 1 unmatching image-pairs for each image\n",
        "# So (2)*87*8 = 1392 pairs in dataset\n",
        "# Label : 1-Match ; 0-Unmatch\n",
        "\n",
        "for i in range(0,87):            #1 - Reenu - [0:86]\n",
        "    source_img = x_train[i]\n",
        "    matching_img_1 = x_train[randint(0,86)]\n",
        "    unmatch_img_1 = x_train[randint(87,695)]\n",
        "    pairs_test.extend([[source_img,matching_img_1],\n",
        "                  [source_img,unmatch_img_1]])\n",
        "    labels_test.extend([1,0])\n",
        "print('Progress: ',len(pairs_test),'/1392')\n",
        "\n",
        "for i in range(87,174):            #2 - Renie - [87:173]\n",
        "    source_img = x_train[i]\n",
        "    matching_img_1 = x_train[randint(87,173)]\n",
        "    unmatch_img_1 = x_train[randint(174,695)]\n",
        "    pairs_test.extend([[source_img,matching_img_1],\n",
        "                  [source_img,unmatch_img_1]])\n",
        "    labels_test.extend([1,0])\n",
        "print('Progress: ',len(pairs_test),'/1392')\n",
        "\n",
        "for i in range(174,261):            #3 - Sandra F - [174:260]\n",
        "    source_img = x_train[i]\n",
        "    matching_img_1 = x_train[randint(174,260)]\n",
        "    unmatch_img_1 = x_train[randint(261,695)]\n",
        "    pairs_test.extend([[source_img,matching_img_1],\n",
        "                  [source_img,unmatch_img_1]])\n",
        "    labels_test.extend([1,0])\n",
        "print('Progress: ',len(pairs_test),'/1392')\n",
        "\n",
        "for i in range(261,348):            #4 - Shoalia - [261:347]\n",
        "    source_img = x_train[i]\n",
        "    matching_img_1 = x_train[randint(261,347)]\n",
        "    unmatch_img_1 = x_train[randint(348,695)]\n",
        "    pairs_test.extend([[source_img,matching_img_1],\n",
        "                  [source_img,unmatch_img_1]])\n",
        "    labels_test.extend([1,0])\n",
        "print('Progress: ',len(pairs_test),'/1392')\n",
        "\n",
        "for i in range(348,435):            #5 - Shwetha Sandeep - [348:434]\n",
        "    source_img = x_train[i]\n",
        "    matching_img_1 = x_train[randint(348,434)]\n",
        "    unmatch_img_1 = x_train[randint(435,695)]\n",
        "    pairs_test.extend([[source_img,matching_img_1],\n",
        "                  [source_img,unmatch_img_1]])\n",
        "    labels_test.extend([1,0])\n",
        "print('Progress: ',len(pairs_test),'/1392')\n",
        "\n",
        "for i in range(435,522):            #6 - Sweta Satish - [435:521]\n",
        "    source_img = x_train[i]\n",
        "    matching_img_1 = x_train[randint(435,521)]\n",
        "    unmatch_img_1 = x_train[randint(0,434)]\n",
        "    pairs_test.extend([[source_img,matching_img_1],\n",
        "                  [source_img,unmatch_img_1]])\n",
        "    labels_test.extend([1,0])\n",
        "print('Progress: ',len(pairs_test),'/1392')\n",
        "\n",
        "for i in range(522,609):            #7 - Tabita - [522:608]\n",
        "    source_img = x_train[i]\n",
        "    matching_img_1 = x_train[randint(522,608)]\n",
        "    unmatch_img_1 = x_train[randint(0,521)]\n",
        "    pairs_test.extend([[source_img,matching_img_1],\n",
        "                  [source_img,unmatch_img_1]])\n",
        "    labels_test.extend([1,0])\n",
        "print('Progress: ',len(pairs_test),'/1392')\n",
        "\n",
        "for i in range(609,696):            #8 - Vivek SP - [609:695]\n",
        "    source_img = x_train[i]\n",
        "    matching_img_1 = x_train[randint(609,695)]\n",
        "    unmatch_img_1 = x_train[randint(0,608)]\n",
        "    pairs_test.extend([[source_img,matching_img_1],\n",
        "                  [source_img,unmatch_img_1]])\n",
        "    labels_test.extend([1,0])\n",
        "print('Progress: ',len(pairs_test),'/1392')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Progress:  174 /1392\n",
            "Progress:  348 /1392\n",
            "Progress:  522 /1392\n",
            "Progress:  696 /1392\n",
            "Progress:  870 /1392\n",
            "Progress:  1044 /1392\n",
            "Progress:  1218 /1392\n",
            "Progress:  1392 /1392\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hU5cLU4LA-g7",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 220
        },
        "outputId": "de83af8d-312f-4871-d062-c24ddcd1ac08"
      },
      "source": [
        "# Dataset visualizer\n",
        "#num = int(input('Enter value between 0 & 6263: '))\n",
        "num = 50\n",
        "f = plt.figure()\n",
        "f.add_subplot(1,2, 1)\n",
        "plt.imshow(pairs_train[num][0])\n",
        "f.add_subplot(1,2, 2)\n",
        "plt.imshow(pairs_train[num][1])\n",
        "plt.show(block=True)\n",
        "print(labels_train[num])"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAXAAAAC6CAYAAAC3HRZZAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\n",
            "text/plain": [
              "<Figure size 432x288 with 2 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "0\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rjLZuLLxN_PR",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 118
        },
        "outputId": "409d5a9c-11fb-4909-d452-2c63350f3512"
      },
      "source": [
        "#Convert labels to Numpy array\n",
        "print('The label is in list format: ',type(labels_train),labels_train[1:20])\n",
        "labels_train = np.asarray(labels_train)\n",
        "print('The labels are now in :', type(labels_train),labels_train[1:20])\n",
        "\n",
        "print('The label is in list format: ',type(labels_test),labels_test[1:20])\n",
        "labels_test = np.asarray(labels_test)\n",
        "print('The labels are now in :', type(labels_test),labels_test[1:20])\n",
        "\n",
        "#Convert pairs to numpy array\n",
        "pairs_train = np.asarray(pairs_train)\n",
        "print(type(pairs_train))\n",
        "pairs_test = np.asarray(pairs_test)\n",
        "print(type(pairs_test))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "The label is in list format:  <class 'list'> [1, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 0, 0, 0, 0, 1, 1]\n",
            "The labels are now in : <class 'numpy.ndarray'> [1 0 0 0 0 0 0 0 1 1 0 0 0 0 0 0 0 1 1]\n",
            "The label is in list format:  <class 'list'> [0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0]\n",
            "The labels are now in : <class 'numpy.ndarray'> [0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0]\n",
            "<class 'numpy.ndarray'>\n",
            "<class 'numpy.ndarray'>\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "b5BH5X8vDacF",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from keras import backend as K\n",
        "\n",
        "def euclidean_distance(vects):\n",
        "    x, y = vects\n",
        "    sum_square = K.sum(K.square(x - y), axis=1, keepdims=True)\n",
        "    return K.sqrt(K.maximum(sum_square, K.epsilon()))\n",
        "\n",
        "\n",
        "input = Input((64,64))\n",
        "x = Flatten()(input)\n",
        "x = Dense(128, activation='relu')(x) #128\n",
        "dense = Model(input, x)\n",
        "\n",
        "input1 = Input((64,64))\n",
        "input2 = Input((64,64))\n",
        "\n",
        "dense1 = dense(input1)\n",
        "dense2 = dense(input2)\n",
        "\n",
        "merge_layer = Lambda(euclidean_distance)([dense1,dense2])\n",
        "dense_layer = Dense(1, activation=\"sigmoid\")(merge_layer)\n",
        "model = Model(inputs=[input1, input2], outputs=dense_layer)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FJOeZH25swuV",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 353
        },
        "outputId": "c3f2af60-ed8f-4a92-896f-907dc3635fed"
      },
      "source": [
        "model.compile(loss = \"binary_crossentropy\", optimizer=\"adam\", metrics=[\"accuracy\"])\n",
        "model.summary()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"model_10\"\n",
            "__________________________________________________________________________________________________\n",
            "Layer (type)                    Output Shape         Param #     Connected to                     \n",
            "==================================================================================================\n",
            "input_14 (InputLayer)           (None, 64, 64)       0                                            \n",
            "__________________________________________________________________________________________________\n",
            "input_15 (InputLayer)           (None, 64, 64)       0                                            \n",
            "__________________________________________________________________________________________________\n",
            "model_9 (Model)                 (None, 256)          1048832     input_14[0][0]                   \n",
            "                                                                 input_15[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "lambda_5 (Lambda)               (None, 1)            0           model_9[1][0]                    \n",
            "                                                                 model_9[2][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "dense_10 (Dense)                (None, 1)            2           lambda_5[0][0]                   \n",
            "==================================================================================================\n",
            "Total params: 1,048,834\n",
            "Trainable params: 1,048,834\n",
            "Non-trainable params: 0\n",
            "__________________________________________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LemAwZkVtDMC",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Training\n",
        "wandb.init(project=\"siamese\")\n",
        "model.fit([pairs_train[:,0], pairs_train[:,1]], labels_train[:],\n",
        "          batch_size=16,\n",
        "          validation_data = ([pairs_test[:,0], pairs_test[:,1]],labels_test[:]),\n",
        "          epochs= 20,\n",
        "          callbacks=[WandbCallback()])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uXVA6ONGbIWE",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "os.chdir(\"/content/drive/My Drive/Colab Notebooks/SNN data/\")\n",
        "model.save('SNN_model.h5py')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0vgKrkw_bil6",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from keras.models import load_model\n",
        "model = load_model('/content/drive/My Drive/Colab Notebooks/SNN data/SNN_model.h5py')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "un83jpLZSCbh",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Predicting output\n",
        "size = 64\n",
        "\n",
        "#Image1\n",
        "file = '/content/drive/My Drive/Colab Notebooks/Project-Sign samples/Input images/5.jpg'\n",
        "test_im1 = cv2.imread(file,0)  # 0 for greyscale\n",
        "plot1 = test_im1\n",
        "test_im1 = cv2.resize(test_im1, dsize=(size, size), interpolation=cv2.INTER_CUBIC)\n",
        "\n",
        "#Image2\n",
        "file = '/content/drive/My Drive/Colab Notebooks/Project-Sign samples/Input images/9.jpg'\n",
        "test_im2 = cv2.imread(file,0)  # 0 for greyscale\n",
        "plot2 = test_im2\n",
        "test_im2 = cv2.resize(test_im2, dsize=(size, size), interpolation=cv2.INTER_CUBIC)\n",
        "\n",
        "#Plotting\n",
        "f = plt.figure()\n",
        "f.add_subplot(1,2, 1)\n",
        "plt.imshow(plot1)\n",
        "f.add_subplot(1,2, 2)\n",
        "plt.imshow(plot2)\n",
        "plt.show(block=True)\n",
        "\n",
        "test_im1 = np.true_divide(test_im1,255)\n",
        "test_im1 = np.asarray(test_im1)\n",
        "test_im2 = np.true_divide(test_im2,255)\n",
        "test_im2 = np.asarray(test_im2)\n",
        "\n",
        "result = model.predict([[test_im1],[test_im2]],steps=None)\n",
        "print(result)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "J1WXSovYUCGp",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#To crop white spaces\n",
        "file = '/content/drive/My Drive/Colab Notebooks/Project-Sign samples/Input images/6.jpg'\n",
        "im = cv2.imread(file,0)\n",
        "im = cv2.resize(im, dsize=(64, 64), interpolation=cv2.INTER_CUBIC)\n",
        "im = np.asarray(im)\n",
        "# Mask of non-black pixels (assuming image has a single channel).\n",
        "mask = im < 255\n",
        "\n",
        "# Coordinates of non-black pixels.\n",
        "coords = np.argwhere(mask)\n",
        "\n",
        "# Bounding box of non-black pixels.\n",
        "x0, y0 = coords.min(axis=0)\n",
        "x1, y1 = coords.max(axis=0) + 1   # slices are exclusive at the top\n",
        "\n",
        "# Get the contents of the bounding box.\n",
        "cropped = im[x0:x1,y0:y1]\n",
        "\n",
        "f = plt.figure()\n",
        "f.add_subplot(1,2, 1)\n",
        "plt.imshow(im)\n",
        "f.add_subplot(1,2, 2)\n",
        "plt.imshow(cropped)\n",
        "plt.show(block=True)"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}