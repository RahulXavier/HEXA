{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Hand_v2 (1).ipynb",
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "1pguHBS5qRpd",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 122
        },
        "outputId": "95dba5e0-c4c0-40ab-a47e-476d9f4541fc"
      },
      "source": [
        "#For authentication from google drive and to link googe drive\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Go to this URL in a browser: https://accounts.google.com/o/oauth2/auth?client_id=947318989803-6bn6qk8qdgf4n4g3pfee6491hc0brc4i.apps.googleusercontent.com&redirect_uri=urn%3aietf%3awg%3aoauth%3a2.0%3aoob&response_type=code&scope=email%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdocs.test%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdrive%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdrive.photos.readonly%20https%3a%2f%2fwww.googleapis.com%2fauth%2fpeopleapi.readonly\n",
            "\n",
            "Enter your authorization code:\n",
            "··········\n",
            "Mounted at /content/drive\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iyC2uHXSqU5_",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "!pip install wandb\n",
        "import wandb\n",
        "from wandb.keras import WandbCallback\n",
        "\n",
        "# This cell contains all the references to libraries that are needed to train a convolutional neural network\n",
        "\n",
        "from __future__ import print_function, division  \n",
        "#To support Py2.0's print function  #To correct ambiguous division operator\n",
        "\n",
        "import numpy as np   #for working with arrays\n",
        "import random #to give a random number between 0 and 1\n",
        "import os #The OS module in Python provides functions for creating and removing a directory (folder), fetching its contents, changing and identifying the current directory, etc.\n",
        "import glob #To find files with a certain extension in a library. Eg: To find .jpg files\n",
        "\n",
        "# https://opencv.org/\n",
        "!apt-get -qq install -y libsm6 libxext6 && pip install -q -U opencv-python\n",
        "import cv2 #OpenCV with Numpy Support\n",
        "import datetime\n",
        "import pandas as pd #For data analysis\n",
        "import time \n",
        "import h5py #To work with HDF5 format, which stores huge amounts of numerical data #https://www.h5py.org/ to store trained file\n",
        "import csv #To handle CSV files (Excel)\n",
        "\n",
        "# https://docs.scipy.org/doc/scipy-1.2.1/reference/generated/scipy.misc.imresize.html\n",
        "from skimage.transform import resize\n",
        "\n",
        "#from sklearn.cross_validation import KFold, train_test_split #To estimate skill of machine learning model #Split to Training and Testing, to avoid overfitting\n",
        "from sklearn.metrics import log_loss, confusion_matrix #To calculate loss function #Matrix to visualize performance\n",
        "from sklearn.utils import shuffle #shuffle data for better training\n",
        "\n",
        "from PIL import Image, ImageChops, ImageOps  #To work with images #For image editing #For automatic filters on images\n",
        "#PIL = Python Imaging Library\n",
        "\n",
        "import matplotlib.pyplot as plt #To replicate plot function in matlab\n",
        "\n",
        "from keras.layers import Dense, Dropout, Flatten, Lambda, ELU, Activation, BatchNormalization\n",
        "\n",
        "from keras.optimizers import SGD, Adam, RMSprop\n",
        "\n",
        "from keras import backend as K #To choose backend(Tensorflow,Theano,CTNK,etc)\n",
        "from keras.callbacks import EarlyStopping, Callback #To stop training epochs if training stops improving, to prevent overfitting #To view staticstics during training\n",
        "from keras.utils import np_utils #Embed NumPy with Keras\n",
        "from keras.preprocessing.image import ImageDataGenerator, load_img, img_to_array #For data augmentation(rotate,resize,shearing etc) #Load image as PIL #To make 3D NumPy array of img\n",
        "from keras import optimizers #Algorithm to update weights\n",
        "from keras.models import Sequential, model_from_json #For layer-by-layer model creation #A type of ANN model\n",
        "from keras.layers import Convolution2D, MaxPooling2D, ZeroPadding2D, Activation, Dropout, Flatten, Dense , Cropping2D #layers in CNN"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "utFokN3CqYOk",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Build a neural network in Keras\n",
        "num_classes=10\n",
        "# Function to resize image to 56x56\n",
        "#def resize_image(image):\n",
        " #   import tensorflow as tf\n",
        " #   return tf.image.resize_images(image,[56,56])\n",
        "\n",
        "# Function to resize image to 64x64\n",
        "row, col, ch = 113, 113, 1\n",
        "\n",
        "model = Sequential()\n",
        "model.add(ZeroPadding2D((1, 1), input_shape=(row, col, ch)))\n",
        "\n",
        "# Resise data within the neural network\n",
        "#model.add(Lambda(resize_image))  #resize images to allow for easy computation\n",
        "\n",
        "# CNN model - Building the model suggested in paper\n",
        "\n",
        "model.add(Convolution2D(filters= 32, kernel_size =(5,5), strides= (2,2), padding='same', name='conv1')) #96\n",
        "model.add(Activation('relu'))\n",
        "model.add(MaxPooling2D(pool_size=(2,2),strides=(2,2), name='pool1'))\n",
        "\n",
        "model.add(Convolution2D(filters= 64, kernel_size =(3,3), strides= (1,1), padding='same', name='conv2'))  #256\n",
        "model.add(Activation('relu'))\n",
        "model.add(MaxPooling2D(pool_size=(2,2),strides=(2,2), name='pool2'))\n",
        "\n",
        "model.add(Convolution2D(filters= 128, kernel_size =(3,3), strides= (1,1), padding='same', name='conv3'))  #256\n",
        "model.add(Activation('relu'))\n",
        "\n",
        "\n",
        "\n",
        "model.add(Flatten())\n",
        "model.add(Dropout(0.5))\n",
        "\n",
        "model.add(Dense(512, name='dense1'))  #1024\n",
        "# model.add(BatchNormalization())\n",
        "model.add(Activation('relu'))\n",
        "model.add(Dropout(0.5))\n",
        "\n",
        "model.add(Dense(256, name='dense2'))  #1024\n",
        "model.add(Activation('relu'))\n",
        "model.add(Dropout(0.5))\n",
        "\n",
        "model.add(Dense(num_classes,name='output'))\n",
        "model.add(Activation('softmax'))  #softmax since output is within 50 classes\n",
        "\n",
        "model.compile(loss='categorical_crossentropy', optimizer=Adam(), metrics=['accuracy'])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5oHLRNK_qn5l",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 68
        },
        "outputId": "9f3060c8-de6c-4b54-d54b-02403eb712c0"
      },
      "source": [
        "# use ImageDataGenerator to preprocess the data\n",
        "from keras.preprocessing.image import ImageDataGenerator\n",
        "\n",
        "# Augment the data that we have to create more training data\n",
        "train_datagen = ImageDataGenerator(rescale = 1./255,\n",
        "                                   rotation_range=0,\n",
        "                                   shear_range = 0,\n",
        "                                   zoom_range = 0)\n",
        "\n",
        "test_datagen = ImageDataGenerator(rescale = 1./255)\n",
        "\n",
        "\n",
        "batchsize = 32 #Default 32\n",
        "# Prepare training data\n",
        "# Select path, Input resolution, input resolution, Batch size, class number.\n",
        "# The batch size is a number of samples processed before the model is updated. https://stats.stackexchange.com/questions/153531/what-is-batch-size-in-neural-network\n",
        "# class_mode selection - https://medium.com/@vijayabhaskar96/tutorial-image-classification-with-keras-flow-from-directory-and-generators-95f75ebe5720\n",
        "training_data = train_datagen.flow_from_directory('/content/drive/My Drive/cnn hw/Training',\n",
        "                                                 target_size = (113, 113),color_mode= 'grayscale',\n",
        "                                                 batch_size = batchsize,\n",
        "                                                 class_mode = 'categorical')\n",
        "# prepare test data\n",
        "valid_data = test_datagen.flow_from_directory('/content/drive/My Drive/cnn hw/Testing',\n",
        "                                            target_size = (113, 113),color_mode= 'grayscale',\n",
        "                                            batch_size = batchsize,\n",
        "                                            class_mode = 'categorical')\n",
        "\n",
        "test_data = test_datagen.flow_from_directory('/content/drive/My Drive/cnn hw/Testing',\n",
        "                                            target_size = (113, 113),color_mode= 'grayscale',\n",
        "                                            batch_size = 1,\n",
        "                                            class_mode = 'categorical')\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Found 2946 images belonging to 10 classes.\n",
            "Found 730 images belonging to 10 classes.\n",
            "Found 730 images belonging to 10 classes.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9NY2_IMqrJW9",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# finally start computation\n",
        "# to improve the model accuracy you can increase the number of steps_per_epoch to e.g. 8000\n",
        "# increase the number of epochs to 5-25\n",
        "# increase the validation steps\n",
        "# this parametters allow for the model to optimize\n",
        "wandb.init(project=\"CNN hand v2\")\n",
        "model.fit_generator(training_data,\n",
        "                         steps_per_epoch = (4000 / batchsize),  #real 4000\n",
        "                         epochs = 30,\n",
        "                         validation_data = valid_data,\n",
        "                         validation_steps = 20,\n",
        "                         callbacks=[WandbCallback()])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "POYZkMZliZJH",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "6095727f-8313-4c30-8123-dadf80a5e1d1"
      },
      "source": [
        "# finally start computation\n",
        "# to improve the model accuracy you can increase the number of steps_per_epoch to e.g. 8000\n",
        "# increase the number of epochs to 5-25\n",
        "# increase the validation steps\n",
        "# this parametters allow for the model to optimize\n",
        "\n",
        "model.fit_generator(training_data,\n",
        "                         steps_per_epoch = (4000 / batchsize),  #real 4000\n",
        "                         epochs = 30,\n",
        "                         validation_data = valid_data,\n",
        "                         validation_steps = 20\n",
        "                         )"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/30\n",
            "124/125 [============================>.] - ETA: 10s - loss: 1.4280 - accuracy: 0.5061"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/keras/utils/data_utils.py:616: UserWarning: The input 15 could not be retrieved. It could be because a worker has died.\n",
            "  UserWarning)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "125/125 [==============================] - 1451s 12s/step - loss: 1.4258 - accuracy: 0.5076 - val_loss: 1.2878 - val_accuracy: 0.5781\n",
            "Epoch 2/30\n",
            "125/125 [==============================] - 40s 320ms/step - loss: 1.2311 - accuracy: 0.5509 - val_loss: 1.2184 - val_accuracy: 0.5426\n",
            "Epoch 3/30\n",
            "125/125 [==============================] - 6s 52ms/step - loss: 1.0902 - accuracy: 0.6060 - val_loss: 0.6914 - val_accuracy: 0.6104\n",
            "Epoch 4/30\n",
            "125/125 [==============================] - 6s 51ms/step - loss: 0.9062 - accuracy: 0.6655 - val_loss: 1.0855 - val_accuracy: 0.6782\n",
            "Epoch 5/30\n",
            "125/125 [==============================] - 6s 51ms/step - loss: 0.6996 - accuracy: 0.7469 - val_loss: 0.5168 - val_accuracy: 0.7666\n",
            "Epoch 6/30\n",
            "125/125 [==============================] - 6s 52ms/step - loss: 0.4697 - accuracy: 0.8330 - val_loss: 0.5911 - val_accuracy: 0.8044\n",
            "Epoch 7/30\n",
            "125/125 [==============================] - 6s 50ms/step - loss: 0.3768 - accuracy: 0.8708 - val_loss: 0.4591 - val_accuracy: 0.8170\n",
            "Epoch 8/30\n",
            "125/125 [==============================] - 6s 50ms/step - loss: 0.2464 - accuracy: 0.9154 - val_loss: 0.3922 - val_accuracy: 0.8859\n",
            "Epoch 9/30\n",
            "125/125 [==============================] - 6s 51ms/step - loss: 0.2266 - accuracy: 0.9214 - val_loss: 0.2967 - val_accuracy: 0.8549\n",
            "Epoch 10/30\n",
            "125/125 [==============================] - 6s 49ms/step - loss: 0.1718 - accuracy: 0.9431 - val_loss: 0.3576 - val_accuracy: 0.8596\n",
            "Epoch 11/30\n",
            "125/125 [==============================] - 6s 49ms/step - loss: 0.1388 - accuracy: 0.9534 - val_loss: 0.4823 - val_accuracy: 0.8707\n",
            "Epoch 12/30\n",
            "125/125 [==============================] - 6s 49ms/step - loss: 0.1816 - accuracy: 0.9479 - val_loss: 0.5124 - val_accuracy: 0.8754\n",
            "Epoch 13/30\n",
            "125/125 [==============================] - 6s 49ms/step - loss: 0.1042 - accuracy: 0.9678 - val_loss: 0.1859 - val_accuracy: 0.8880\n",
            "Epoch 14/30\n",
            "125/125 [==============================] - 6s 49ms/step - loss: 0.0757 - accuracy: 0.9741 - val_loss: 0.3619 - val_accuracy: 0.8565\n",
            "Epoch 15/30\n",
            "125/125 [==============================] - 6s 49ms/step - loss: 0.0813 - accuracy: 0.9756 - val_loss: 0.1593 - val_accuracy: 0.8707\n",
            "Epoch 16/30\n",
            "125/125 [==============================] - 6s 48ms/step - loss: 0.0569 - accuracy: 0.9815 - val_loss: 0.1733 - val_accuracy: 0.8813\n",
            "Epoch 17/30\n",
            "125/125 [==============================] - 6s 50ms/step - loss: 0.0720 - accuracy: 0.9788 - val_loss: 0.4871 - val_accuracy: 0.8502\n",
            "Epoch 18/30\n",
            "125/125 [==============================] - 6s 50ms/step - loss: 0.0979 - accuracy: 0.9751 - val_loss: 0.2270 - val_accuracy: 0.8849\n",
            "Epoch 19/30\n",
            "125/125 [==============================] - 6s 49ms/step - loss: 0.0506 - accuracy: 0.9835 - val_loss: 0.6009 - val_accuracy: 0.8707\n",
            "Epoch 20/30\n",
            "125/125 [==============================] - 6s 48ms/step - loss: 0.0353 - accuracy: 0.9879 - val_loss: 0.0565 - val_accuracy: 0.8975\n",
            "Epoch 21/30\n",
            "125/125 [==============================] - 6s 48ms/step - loss: 0.0232 - accuracy: 0.9926 - val_loss: 0.0717 - val_accuracy: 0.8722\n",
            "Epoch 22/30\n",
            "125/125 [==============================] - 6s 49ms/step - loss: 0.0329 - accuracy: 0.9902 - val_loss: 0.5308 - val_accuracy: 0.8817\n",
            "Epoch 23/30\n",
            "125/125 [==============================] - 6s 47ms/step - loss: 0.0386 - accuracy: 0.9874 - val_loss: 0.3305 - val_accuracy: 0.8801\n",
            "Epoch 24/30\n",
            "125/125 [==============================] - 6s 49ms/step - loss: 0.0334 - accuracy: 0.9902 - val_loss: 1.0888 - val_accuracy: 0.8594\n",
            "Epoch 25/30\n",
            "125/125 [==============================] - 6s 49ms/step - loss: 0.0557 - accuracy: 0.9838 - val_loss: 0.1725 - val_accuracy: 0.9022\n",
            "Epoch 26/30\n",
            "125/125 [==============================] - 6s 48ms/step - loss: 0.0396 - accuracy: 0.9887 - val_loss: 0.6206 - val_accuracy: 0.8833\n",
            "Epoch 27/30\n",
            "125/125 [==============================] - 6s 51ms/step - loss: 0.0253 - accuracy: 0.9906 - val_loss: 0.4163 - val_accuracy: 0.8533\n",
            "Epoch 28/30\n",
            "125/125 [==============================] - 6s 51ms/step - loss: 0.0624 - accuracy: 0.9837 - val_loss: 0.6107 - val_accuracy: 0.8565\n",
            "Epoch 29/30\n",
            "125/125 [==============================] - 6s 47ms/step - loss: 0.0225 - accuracy: 0.9926 - val_loss: 0.0638 - val_accuracy: 0.8738\n",
            "Epoch 30/30\n",
            "125/125 [==============================] - 6s 50ms/step - loss: 0.0217 - accuracy: 0.9929 - val_loss: 0.4267 - val_accuracy: 0.8691\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.callbacks.callbacks.History at 0x7f4baa4d6dd8>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZhNhYIypVkqX",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IUskWkOkV3BF",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "seC-VO9orQas",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#To save training data\n",
        "#To save whole data - classifier.save(filepath) , To save just weights without architecture - classifier.save_weights(filepath)\n",
        "os.chdir(\"/content/drive/cnn hw/\")\n",
        "#classifier.save_model('location') , add architecture seperately\n",
        "classifier.save('model1.h5py')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zKGweRv4rSVE",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#To load training data\n",
        "from keras.models import load_model\n",
        "classifier = load_model('/content/drive/cnn hw/model1.h5py')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3G4NkA_urrN9",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# for resize\n",
        "\n",
        "import os\n",
        "import glob\n",
        "import  PIL\n",
        "from PIL import Image\n",
        "from random import sample \n",
        "\n",
        "\n",
        "images = []\n",
        "path_to_files = os.path.join(r'C:\\Users\\ShaiZ\\Desktop\\hand\\1', '*')\n",
        "for filename in sorted(glob.glob(path_to_files)):\n",
        "    image_name = filename.split('/')[-1]\n",
        "    file, ext = os.path.splitext(image_name)\n",
        "    im = Image.open(filename)\n",
        "    cur_width = im.size[0]\n",
        "    cur_height = im.size[1]\n",
        "\n",
        "    # print(cur_width, cur_height)\n",
        "    height_fac = 113 / cur_height\n",
        "\n",
        "    new_width = int(cur_width * height_fac)\n",
        "    size = new_width, 113\n",
        "\n",
        "    imresize = im.resize((size), Image.ANTIALIAS)  # Resize so height = 113 while keeping aspect ratio\n",
        "    now_width = imresize.size[0]\n",
        "    now_height = imresize.size[1]\n",
        "    # Generate crops of size 113x113 from this resized image and keep random 10% of crops\n",
        "\n",
        "    avail_x_points = list(range(0, now_width - 113 ))# total x start points are from 0 to width -113\n",
        "\n",
        "    # Pick random x%\n",
        "    factor = 0.05\n",
        "    pick_num = int(len(avail_x_points)*factor)\n",
        "    \n",
        "    random_startx = sample(avail_x_points,  pick_num)\n",
        "    k=0\n",
        "    for start in random_startx:\n",
        "        imcrop = imresize.crop((start, 0, start+113, 113))\n",
        "        t=str(k)\n",
        "        imcrop.save(file +\"new \"+t +\".png\" , \"PNG\")\n",
        "        k=k+1\n",
        "        \n"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}